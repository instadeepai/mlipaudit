"""ABC definition defining common benchmarking interface."""

from abc import ABC, abstractmethod
from pathlib import Path
from typing import Any

from mlip.models import ForceField
from pydantic import BaseModel


class BenchmarkResult(BaseModel):
    """A base model for all benchmark results."""


class ModelOutput(BaseModel):
    """A base model for all intermediate model outputs."""


class Benchmark(ABC):
    """An Abstract Base Class for structuring MLIP benchmark calculations.

    This class uses the Template Method pattern. Each concrete benchmark
    must implement the `run_model` and `analyze` methods. Benchmarks must
    be designed to first call `run_model` followed by `analyze`. Intermediate
    calculations generated by `run_model` will be stored in the instance variable
    `model_output`. Results generated by `analyze` will be stored in the instance
    variable `model_output`.

    Subclasses should also define the class attribute `name`, giving the
    benchmark a unique name, as well as `input_data_url` if necessary, specifying where
    any input data should be downloaded from.
    """

    name: str | None = None
    input_data_url: str | None = None

    def __init__(
        self,
        force_field: ForceField,
        fast_dev_run: bool = False,
        data_input_dir: str | Path = "./data",
    ) -> None:
        """Initializes the benchmark.

        Args:
            force_field: The force field model to be benchmarked.
            fast_dev_run: Whether to do a fast developer run. Subclasses
                should ensure that when True, their benchmark runs in a
                much shorter timeframe, by running on a reduced number of
                test cases, for instance.
            data_input_dir: The local input data directory. Defaults to
                "./data/{benchmark_name}".
        """
        self.force_field = force_field
        self.fast_dev_run = fast_dev_run
        self.data_input_dir = Path(data_input_dir)

        self.model_output: ModelOutput | None = None
        self.results: BenchmarkResult | None = None

    def __init_subclass__(cls, **kwargs: Any):
        """Called when a class inherits from `Benchmark`.

        Used to validate that the required class attributes are defined.
        """
        super().__init_subclass__(**kwargs)
        if cls.name is None:
            raise NotImplementedError(
                f"{cls.__name__} must override the `name` attribute."
            )

    def __download_data(self) -> None:
        """Download the data from the data input directory if not already cached."""
        # is_empty = not any(self.data_input_dir.iterdir())

        pass  # Add the rest of the logic here

    @abstractmethod
    def run_model(self) -> None:
        """Generates any necessary data with `self.force_field`.

        Subclasses must implement this method. Raw data from simulations,
        single-point energy calculations or other types of calculations
        will be stored in the instance variable `model_output`.
        """
        pass

    @abstractmethod
    def analyze(self) -> BenchmarkResult:
        """Performs all post-inference or simulation analysis.

        Subclasses must implement this method. This method
        processes the raw data generated from the generation step
        to compute final metrics.

        Returns:
            A class-specific instance of `BenchmarkResult`.
        """
        pass
